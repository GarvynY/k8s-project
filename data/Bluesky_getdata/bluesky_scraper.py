import time
from datetime import datetime, timedelta
from atproto import Client, exceptions
import pandas as pd
import matplotlib.pyplot as plt
import os
import re
from snownlp import SnowNLP
import sys
from dateutil import parser
# ================= é…ç½®åŒºåŸŸ =================
CONFIG = {
    "USERNAME": "linyaozhou.bsky.social",  # ç”¨æˆ·å
    "APP_PASSWORD": "btpz-wrf6-7usi-spjj",  # åº”ç”¨å¯†ç 
    "SEARCH_KEYWORD": ['Australia Election', 'AusPol', 'AUSElection', 'ausvotes2025',
                    '#ausvotes2025', 'auspol2025', '#auspol2025', 'Albanese',
                    'Dutton', 'Bandt', 'Labor', 'Liberal', 'Greens'],  # æœç´¢å…³é”®è¯
    "DATA_FILE": os.path.join(os.path.dirname(__file__), "bluesky_data.csv"),  # æ•°æ®æ–‡ä»¶è·¯å¾„
    "IMG_DIR": os.path.join(os.path.dirname(__file__), "charts"),  # å›¾è¡¨ç›®å½•
    "FETCH_INTERVAL": 60,  # æŠ“å–é—´éš”(ç§’)
    "MAX_PAGES": 5,  # æœ€å¤§é¡µæ•°
    "PAGE_SIZE": 100,  # æ¯é¡µå¤§å°
    "MAX_RETRIES": 3,  # æ–°å¢é‡è¯•æ¬¡æ•°
    "DEBUG": True  # è°ƒè¯•æ¨¡å¼
}


# ===========================================

class BlueskyAnalyzer:
    def __init__(self, config):
        self.config = config
        self.client = None
        self.setup_directories()

    def setup_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•ç»“æ„"""
        os.makedirs(self.config["IMG_DIR"], exist_ok=True)
        if not os.path.exists(self.config["DATA_FILE"]):
            with open(self.config["DATA_FILE"], 'w', encoding='utf-8') as f:
                f.write("author,content,time,likes,sentiment,url,post_time_of_day,post_day_of_week,sentiment_score,emotion_label,location,geolocation\n")


    def log(self, message):
        """å¸¦æ—¶é—´æˆ³çš„æ—¥å¿—è®°å½•"""
        if self.config["DEBUG"]:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            print(f"[{timestamp}] {message}")

    def connect_bluesky(self):
        """å»ºç«‹Blueskyè¿æ¥"""
        try:
            self.client = Client()
            profile = self.client.login(
                self.config["USERNAME"],
                self.config["APP_PASSWORD"]
            )
            self.log(f"âœ… ç™»å½•æˆåŠŸ @{profile.handle}")
            return True
        except exceptions.UnauthorizedError:
            self.log("âŒ è®¤è¯å¤±è´¥ï¼šè¯·æ£€æŸ¥ç”¨æˆ·åå’ŒAPPå¯†ç ")
        except exceptions.NetworkError:
            self.log("âŒ ç½‘ç»œé”™è¯¯ï¼šè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
        except Exception as e:
            self.log(f"âŒ è¿æ¥å¼‚å¸¸: {str(e)}")
        return False

    def analyze_sentiment(self, text):
        """è¿”å›æƒ…æ„Ÿåˆ†æ•°å’Œæ ‡ç­¾"""
        if not isinstance(text, str) or len(text.strip()) < 5:
            return 0.0, 'neutral'

        text = re.sub(r'http\S+|@\w+|#\w+|[ã€ã€‘\n]', ' ', text.strip())

        try:
            s = SnowNLP(text)
            score = s.sentiments

            # å…³é”®è¯åŠ æƒï¼ˆä¿æŒç°æœ‰é€»è¾‘ï¼‰
            positive_words = ['æ”¯æŒ', 'å¥½', 'æ»¡æ„', 'èƒœåˆ©', 'èµæˆ', 'å–œæ¬¢']
            negative_words = ['åå¯¹', 'å·®', 'æŠ—è®®', 'å¤±è´¥', 'è°´è´£', 'è®¨åŒ']

            score += 0.15 * any(w in text for w in positive_words)
            score -= 0.15 * any(w in text for w in negative_words)

            score = max(0, min(score, 1))  # é™åˆ¶èŒƒå›´åœ¨[0,1]
            label = 'positive' if score > 0.7 else 'negative' if score < 0.3 else 'neutral'

            self.log(f"åˆ†æ: {text[:50]}... â†’ å¾—åˆ†: {score:.2f} â†’ æ ‡ç­¾: {label}")
            return score * 2 - 1, label  # è½¬ä¸º [-1, 1] èŒƒå›´
        except Exception as e:
            self.log(f"åˆ†æå¼‚å¸¸: {str(e)}")
            return 0.0, 'neutral'

    def fetch_posts_with_retry(self):
        """å¸¦é‡è¯•æœºåˆ¶çš„è·å–å¸–å­æ•°æ®"""
        for attempt in range(1, self.config["MAX_RETRIES"] + 1):
            try:
                self.log(f"å°è¯•ç¬¬ {attempt} æ¬¡è·å–æ•°æ®...")
                posts = self.fetch_posts()
                if posts:
                    return posts
                time.sleep(2)  # ç­‰å¾…2ç§’åé‡è¯•
            except Exception as e:
                self.log(f"âŒ ç¬¬ {attempt} æ¬¡å°è¯•å¤±è´¥: {str(e)}")
                if attempt == self.config["MAX_RETRIES"]:
                    return None
                time.sleep(5)  # ç­‰å¾…æ›´é•¿æ—¶é—´åé‡è¯•
        return None

    def fetch_posts(self):
        """è·å–å¸–å­æ•°æ®ï¼ˆå¤šå…³é”®è¯æ”¯æŒï¼‰"""
        if not self.client and not self.connect_bluesky():
            return None

        try:
            self.log(f"ğŸ” æœç´¢å…³é”®è¯åˆ—è¡¨: {self.config['SEARCH_KEYWORD']}")
            all_posts = []

            for keyword in self.config["SEARCH_KEYWORD"]:
                self.log(f"ğŸ” æ­£åœ¨æœç´¢å…³é”®è¯: '{keyword}'")
                cursor = None

                for page in range(1, self.config["MAX_PAGES"] + 1):
                    params = {
                        'q': keyword,
                        'limit': self.config["PAGE_SIZE"],
                        'cursor': cursor
                    }

                    response = self.client.app.bsky.feed.search_posts(params=params)

                    post_count = len(response.posts) if response.posts else 0
                    self.log(f"ğŸ“„ ç¬¬ {page} é¡µè·å– {post_count} æ¡ç»“æœ")

                    if not response.posts:
                        break

                    all_posts.extend(response.posts)
                    cursor = response.cursor
                    time.sleep(1)

            self.log(f"ğŸ“Š å…±è·å–åŸå§‹å¸–å­æ•°: {len(all_posts)}")
            return self.process_posts(all_posts)

        except Exception as e:
            self.log(f"âŒ æœç´¢å¤±è´¥: {str(e)}")
            return None



    def process_posts(self, posts):
        """å¤„ç†åŸå§‹å¸–å­æ•°æ®"""
        processed = []
        for post in posts[:200]:
            try:
                content = post.record.text
                if not content or len(content) < 10:
                    continue

                timestamp = parser.parse(post.indexed_at)
                hour = timestamp.hour
                post_time_of_day = (
                    "Night" if hour < 6 else
                    "Morning" if hour < 12 else
                    "Afternoon" if hour < 18 else
                    "Evening"
                )
                post_day_of_week = timestamp.strftime('%A')

                sentiment_score, emotion_label = self.analyze_sentiment(content)

                location = getattr(post.author, "description", "")
                geolocation = ""  # Blueskyç›®å‰ä¸æä¾›æ˜ç¡®çš„ç»çº¬åº¦å­—æ®µ

                processed.append({
                    'author': post.author.handle,
                    'content': content,
                    'time': post.indexed_at,
                    'likes': getattr(post, 'like_count', 0),
                    'sentiment': emotion_label,
                    'url': f"https://bsky.app/profile/{post.author.handle}/post/{post.uri.split('/')[-1]}",
                    'post_time_of_day': post_time_of_day,
                    'post_day_of_week': post_day_of_week,
                    'sentiment_score': sentiment_score,
                    'emotion_label': emotion_label,
                    'location': location,
                    'geolocation': geolocation
                })

            except Exception as e:
                self.log(f"â­ï¸ è·³è¿‡å¼‚å¸¸æ•°æ®: {str(e)}")

        return processed

    def save_and_analyze(self, new_data):
        """ä¿å­˜æ•°æ®å¹¶ç”Ÿæˆç»Ÿè®¡"""
        if not new_data:
            self.log("âš ï¸ æ— æ–°æ•°æ®éœ€è¦ä¿å­˜")
            return None, 0

        try:
            # è¯»å–ç°æœ‰æ•°æ®
            if os.path.exists(self.config["DATA_FILE"]) and os.path.getsize(self.config["DATA_FILE"]) > 10:
                existing_df = pd.read_csv(self.config["DATA_FILE"])
            else:
                existing_df = pd.DataFrame()

            # åˆå¹¶æ•°æ®
            new_df = pd.DataFrame(new_data)
            combined_df = pd.concat([existing_df, new_df]).drop_duplicates(subset=['content'])
            new_count = len(combined_df) - len(existing_df)

            # ä¿å­˜æ•°æ®
            combined_df.to_csv(self.config["DATA_FILE"], index=False, encoding='utf-8-sig')
            self.log(f"ğŸ’¾ ä¿å­˜æˆåŠŸ: æ–°å¢ {new_count} æ¡ï¼Œæ€»è®¡ {len(combined_df)} æ¡")

            return combined_df, new_count

        except Exception as e:
            self.log(f"âŒ ä¿å­˜å¤±è´¥: {str(e)}")
            return None, 0

    def generate_visualization(self, df):
        """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼ˆä¿®å¤ç‰ˆï¼‰"""
        if df is None or len(df) == 0:
            self.log("âš ï¸ æ— æ•°æ®å¯å¯è§†åŒ–")
            return False

        try:
            # æ•°æ®é¢„å¤„ç†
            df['date'] = pd.to_datetime(df['time']).dt.date
            df_counts = df.groupby(['date', 'sentiment']).size().unstack(fill_value=0)

            # åˆ›å»ºå›¾è¡¨
            plt.figure(figsize=(12, 6))

            # é¢œè‰²æ˜ å°„
            colors = {'positive': '#4CAF50', 'neutral': '#FFC107', 'negative': '#F44336'}

            # ç»˜åˆ¶æ¯ç§æƒ…æ„Ÿçš„è¶‹åŠ¿çº¿
            for sentiment in df_counts.columns:
                if sentiment in colors:
                    df_counts[sentiment].plot(
                        kind='line',
                        marker='o',
                        label=sentiment,
                        color=colors[sentiment],
                        linewidth=2
                    )

            # å›¾è¡¨è£…é¥°
            plt.title(f"å…³é”®è¯: {self.config['SEARCH_KEYWORD']}\næ€»æ•°æ®é‡: {len(df)}æ¡", pad=20)
            plt.xlabel("æ—¥æœŸ", labelpad=10)
            plt.ylabel("å¸–å­æ•°é‡", labelpad=10)
            plt.legend(title="æƒ…æ„Ÿå€¾å‘")
            plt.grid(True, linestyle='--', alpha=0.6)
            plt.tight_layout()

            # ä¿å­˜å›¾è¡¨
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            img_path = os.path.join(self.config["IMG_DIR"], f"sentiment_{timestamp}.png")
            plt.savefig(img_path, bbox_inches='tight', dpi=120)
            plt.close()

            self.log(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜: {img_path}")
            return True

        except Exception as e:
            self.log(f"âŒ å¯è§†åŒ–å¤±è´¥: {str(e)}")
            return False

    @staticmethod
    def show_summary(df, new_count):
        """æ˜¾ç¤ºç»Ÿè®¡æ‘˜è¦"""
        print("\n" + "=" * 50)
        print(f"ğŸ“… åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
        print("-" * 50)

        stats = df['sentiment'].value_counts()
        print(f"ğŸ“Œ æ–°å¢æ•°æ®: {new_count} æ¡")
        print(f"ğŸ“¦ æ€»è®¡æ•°æ®: {len(df)} æ¡")
        print("\nğŸ’– æƒ…æ„Ÿåˆ†å¸ƒ:")
        print(f"  ğŸ‘ ç§¯æ: {stats.get('positive', 0)} æ¡")
        print(f"  ğŸ˜ ä¸­æ€§: {stats.get('neutral', 0)} æ¡")
        print(f"  ğŸ‘ æ¶ˆæ: {stats.get('negative', 0)} æ¡")

        if not df.empty:
            latest = pd.to_datetime(df['time']).max()
            oldest = pd.to_datetime(df['time']).min()
            print(f"\nâ³ æ—¶é—´èŒƒå›´: {oldest.strftime('%Y-%m-%d')} è‡³ {latest.strftime('%Y-%m-%d')}")

        print("=" * 50 + "\n")

    def run_analysis(self):
        """æ‰§è¡Œå•æ¬¡åˆ†æ"""
        posts = self.fetch_posts_with_retry()
        if not posts:
            self.log("âš ï¸ æ— æ³•è·å–ä»»ä½•æ•°æ®")
            return False

        df, new_count = self.save_and_analyze(posts)
        if df is not None:
            self.generate_visualization(df)
            self.show_summary(df, new_count)
            return True
        return False

    def continuous_monitoring(self):
        """æŒç»­ç›‘æ§æ¨¡å¼"""
        try:
            while True:
                if not self.run_analysis():
                    self.log("âš ï¸ æœ¬æ¬¡åˆ†ææœªè·å–æ•°æ®")

                next_run = datetime.now() + timedelta(seconds=self.config["FETCH_INTERVAL"])
                self.log(f"â° ä¸‹æ¬¡è¿è¡Œ: {next_run.strftime('%H:%M:%S')}")

                for _ in range(self.config["FETCH_INTERVAL"]):
                    time.sleep(1)

        except KeyboardInterrupt:
            self.log("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­ï¼Œç¨‹åºå®‰å…¨é€€å‡º")
        finally:
            if self.client:
                self.log("ğŸ”’ å·²æ–­å¼€Blueskyè¿æ¥")


if __name__ == "__main__":
    analyzer = BlueskyAnalyzer(CONFIG)

    print(f"""
ğŸŒŸ Bluesky èˆ†æƒ…åˆ†æç³»ç»Ÿ v2.3 ğŸŒŸ
{"-" * 40}
ğŸ” å…³é”®è¯: {CONFIG['SEARCH_KEYWORD']}
ğŸ“ æ•°æ®æ–‡ä»¶: {os.path.abspath(CONFIG['DATA_FILE'])}
ğŸ“Š å›¾è¡¨ç›®å½•: {os.path.abspath(CONFIG['IMG_DIR'])}
ğŸ”„ æ›´æ–°é—´éš”: {CONFIG['FETCH_INTERVAL']}ç§’
{"-" * 40}
    """)

    if len(sys.argv) > 1 and sys.argv[1] == "--once":
        analyzer.run_analysis()
    else:
        print("è¿›å…¥æŒç»­ç›‘æ§æ¨¡å¼ (Ctrl+C é€€å‡º)\n")
        analyzer.continuous_monitoring()
