{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e3f01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — NLTK 配置，写死数据目录，确保在导入 stopwords 前设置 —\n",
    "NLTK_DATA_PATH = \"/home/jovyan/work/repo/frontend/source_codes/nltk_data\"\n",
    "os.environ[\"NLTK_DATA\"] = NLTK_DATA_PATH\n",
    "nltk.data.path.insert(0, NLTK_DATA_PATH)\n",
    "# 如果还没下载过 stopwords，就下载到上述目录\n",
    "nltk.download(\"stopwords\", download_dir=NLTK_DATA_PATH, quiet=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a123c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bb889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fef9b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed60b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import HeatMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a281c83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch8 import Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ae92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — 屏蔽 Elasticsearch 不安全 TLS 警告 —\n",
    "warnings.filterwarnings(\"ignore\", message=\".*verify_certs=False is insecure.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c805d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — 确保 GeoJSON 文件存在，否则下载 —\n",
    "GEOJSON_PATH = \"/home/jovyan/work/repo/frontend/source_codes/australia_states.geojson\"\n",
    "GEOJSON_URL = (\n",
    "    \"https://raw.githubusercontent.com/\"\n",
    "    \"codeforgermany/click_that_hood/\"\n",
    "    \"main/public/data/australia.geojson\"\n",
    ")\n",
    "if not os.path.exists(GEOJSON_PATH):\n",
    "    print(f\"GeoJSON not found at {GEOJSON_PATH}, downloading…\")\n",
    "    resp = requests.get(GEOJSON_URL)\n",
    "    resp.raise_for_status()\n",
    "    with open(GEOJSON_PATH, \"wb\") as f:\n",
    "        f.write(resp.content)\n",
    "    print(\"GeoJSON download complete.\")\n",
    "with open(GEOJSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    australia = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e36d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — 加载 WordCloud 需要的 mask 图像 —\n",
    "MASK_PATH = \"/home/jovyan/work/repo/frontend/source_codes/australia_mask1.png\"\n",
    "if not os.path.exists(MASK_PATH):\n",
    "    raise FileNotFoundError(f\"Mask image not found: {MASK_PATH}\")\n",
    "mask_image = np.array(Image.open(MASK_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a66920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — 初始化 Elasticsearch 客户端 —\n",
    "es = Elasticsearch(\n",
    "    [\"https://elasticsearch-master.elastic.svc.cluster.local:9200\"],\n",
    "    basic_auth=(\"elastic\", \"elastic\"),\n",
    "    verify_certs=False\n",
    ")\n",
    "assert es.ping(), \"Failed to connect to Elasticsearch\"\n",
    "print(\"Elasticsearch connection successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64dc4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — 定义城市到经纬度的映射 —\n",
    "city_coords = {\n",
    "    'Sydney':    (-33.8688, 151.2093),\n",
    "    'Melbourne': (-37.8136, 144.9631),\n",
    "    'Brisbane':  (-27.4698, 153.0251),\n",
    "    'Perth':     (-31.9505, 115.8605),\n",
    "    'Adelaide':  (-34.9285, 138.6007),\n",
    "    'Hobart':    (-42.8821, 147.3272),\n",
    "    'Darwin':    (-12.4634, 130.8456),\n",
    "    'Canberra':  (-35.2809, 149.1300)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a9ac86",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# — 合并 NLTK 自带 + WordCloud 默认 + 自定义停用词 —\n",
    "custom_stopwords = {\n",
    "    \"election\", \"government\", \"campaign\", \"vote\", \"voting\",\n",
    "    \"https\", \"http\", \"www\", \"com\", \"co\", \"amp\", \"rt\", \"via\",\n",
    "    \"australia\", \"australian\", \"sydney\", \"melbourne\", \"nsw\", \"vic\", \"qld\",\n",
    "    \"said\", \"says\", \"like\", \"think\", \"know\", \"also\", \"one\", \"new\", \"today\",\n",
    "    \"people\"\n",
    "}\n",
    "nltk_sw = set(stopwords.words('english'))\n",
    "combined_stopwords = nltk_sw.union(STOPWORDS).union(custom_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68058e4f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def fetch_filtered_data(start_date, end_date, max_docs=30000, batch_size=1000):\n",
    "    \"\"\"Fetch up to max_docs posts between start_date and end_date via Scroll API.\"\"\"\n",
    "    query = {\n",
    "        \"size\": batch_size,\n",
    "        \"query\": {\n",
    "            \"range\": {\n",
    "                \"created_at\": {\n",
    "                    \"gte\": start_date.strftime('%Y-%m-%d'),\n",
    "                    \"lte\": end_date.strftime('%Y-%m-%d')\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    page = es.search(index=\"election_v2\", body=query, scroll=\"2m\")\n",
    "    scroll_id = page[\"_scroll_id\"]\n",
    "    hits = page[\"hits\"][\"hits\"]\n",
    "    records = []\n",
    "    while hits and len(records) < max_docs:\n",
    "        for hit in hits:\n",
    "            if len(records) >= max_docs:\n",
    "                break\n",
    "            src = hit[\"_source\"]\n",
    "            loc = src.get(\"location\")\n",
    "            if not loc:\n",
    "                continue\n",
    "            records.append({\n",
    "                \"created_at\": pd.to_datetime(src[\"created_at\"]),\n",
    "                \"emotion_label\": src.get(\"emotion_label\"),\n",
    "                \"post_time_of_day\": src.get(\"post_time_of_day\"),\n",
    "                \"location\": loc,\n",
    "                \"content\": src.get(\"content\", \"\")\n",
    "            })\n",
    "        page = es.scroll(scroll_id=scroll_id, scroll=\"2m\")\n",
    "        scroll_id = page[\"_scroll_id\"]\n",
    "        hits = page[\"hits\"][\"hits\"]\n",
    "    es.clear_scroll(scroll_id=scroll_id)\n",
    "\n",
    "    if not records:\n",
    "        return pd.DataFrame(columns=[\n",
    "            \"created_at\",\"emotion_label\",\"post_time_of_day\",\n",
    "            \"location\",\"latitude\",\"longitude\",\"content\"\n",
    "        ])\n",
    "    df = pd.DataFrame(records)\n",
    "    df[[\"latitude\",\"longitude\"]] = df[\"location\"].apply(\n",
    "        lambda loc: pd.Series(city_coords.get(loc, (None, None)))\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee36e69",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def prepare_map_data(df):\n",
    "    \"\"\"Filter invalid coords, map city to state, return state counts & heat points.\"\"\"\n",
    "    df2 = df.dropna(subset=[\"location\",\"latitude\",\"longitude\"]).copy()\n",
    "    state_map = {\n",
    "        'Sydney': 'New South Wales',   'Melbourne': 'Victoria',\n",
    "        'Brisbane': 'Queensland',       'Perth': 'Western Australia',\n",
    "        'Adelaide': 'South Australia',  'Hobart': 'Tasmania',\n",
    "        'Darwin': 'Northern Territory', 'Canberra': 'Australian Capital Territory'\n",
    "    }\n",
    "    df2[\"state\"] = df2[\"location\"].map(state_map)\n",
    "    state_counts = df2.groupby(\"state\").size().reset_index(name=\"count\")\n",
    "    heat_points = df2[[\"latitude\",\"longitude\"]].values.tolist()\n",
    "    return state_counts, heat_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039cfca6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def draw_map(df, start_date, end_date, show_choro=True, show_heat=True):\n",
    "    \"\"\"Draw choropleth and/or heatmap of posts.\"\"\"\n",
    "    sc, hp = prepare_map_data(df)\n",
    "    print(f\"Date range: {start_date} to {end_date} | Total posts: {len(df)}\")\n",
    "    if sc.empty:\n",
    "        print(\"No data to display\")\n",
    "        return\n",
    "    cnt = sc[\"count\"]\n",
    "    bins = list(np.linspace(cnt.min(), cnt.max(), 6))\n",
    "    m = folium.Map(location=[-25.27,133.77], tiles=\"CartoDB positron\",\n",
    "                   zoom_start=4, min_zoom=4, max_zoom=6)\n",
    "    bounds = [[-44,112],[-10,154]]\n",
    "    m.fit_bounds(bounds)\n",
    "    m.options[\"maxBounds\"] = bounds\n",
    "    m.options[\"maxBoundsViscosity\"] = 1.0\n",
    "\n",
    "    if show_choro:\n",
    "        folium.Choropleth(\n",
    "            geo_data=australia,\n",
    "            data=sc,\n",
    "            columns=[\"state\",\"count\"],\n",
    "            key_on=\"feature.properties.name\",\n",
    "            fill_color=\"Blues\",\n",
    "            threshold_scale=bins,\n",
    "            fill_opacity=0.6,\n",
    "            line_opacity=0.3,\n",
    "            legend_name=\"Post Count\"\n",
    "        ).add_to(m)\n",
    "        folium.GeoJson(australia, style_function=lambda feat: {\n",
    "            \"color\":\"#333\",\"weight\":0.5,\"fillOpacity\":0\n",
    "        }).add_to(m)\n",
    "\n",
    "    if show_heat:\n",
    "        HeatMap(data=hp, radius=12, blur=6, max_zoom=6,\n",
    "                gradient={0.0:'#deebf7',0.25:'#9ecae1',\n",
    "                          0.5:'#6baed6',0.75:'#3182bd',1.0:'#08519c'}\n",
    "        ).add_to(m)\n",
    "\n",
    "    display(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b8dd9",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def draw_sentiment_chart(df):\n",
    "    \"\"\"Plot bar chart of post counts by state & sentiment.\"\"\"\n",
    "    if df.empty or \"emotion_label\" not in df:\n",
    "        print(\"No sentiment data\")\n",
    "        return\n",
    "    df2 = df.dropna(subset=[\"location\",\"emotion_label\"]).copy()\n",
    "    smap = {\n",
    "        'Sydney': 'New South Wales',   'Melbourne': 'Victoria',\n",
    "        'Brisbane': 'Queensland',       'Perth': 'Western Australia',\n",
    "        'Adelaide': 'South Australia',  'Hobart': 'Tasmania',\n",
    "        'Darwin': 'Northern Territory', 'Canberra': 'Australian Capital Territory'\n",
    "    }\n",
    "    df2[\"state\"] = df2[\"location\"].map(smap)\n",
    "    agg = df2.groupby([\"state\",\"emotion_label\"]).size().reset_index(name=\"count\")\n",
    "    plt.figure(figsize=(12,6))\n",
    "    palette = dict(zip(\n",
    "        agg[\"emotion_label\"].unique(),\n",
    "        sns.color_palette(\"Blues\", n_colors=agg[\"emotion_label\"].nunique())\n",
    "    ))\n",
    "    sns.barplot(data=agg, x=\"state\", y=\"count\", hue=\"emotion_label\", palette=palette)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.title(\"Posts by State & Sentiment\")\n",
    "    plt.tight_layout()\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f273d1c5",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def draw_wordcloud(df, start_date, end_date):\n",
    "    \"\"\"Generate noun word cloud from post content.\"\"\"\n",
    "    if df.empty or \"content\" not in df:\n",
    "        print(\"No text data\")\n",
    "        return\n",
    "    text = \" \".join(df[\"content\"].dropna().astype(str)).lower()\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tagged = pos_tag(text.split())\n",
    "    nouns = [\n",
    "        w for w,t in tagged\n",
    "        if t.startswith(\"NN\") and w.isalpha() and w not in combined_stopwords\n",
    "    ]\n",
    "    if not nouns:\n",
    "        print(\"No valid words\")\n",
    "        return\n",
    "    freqs = Counter(nouns)\n",
    "    wc = WordCloud(\n",
    "        width=800, height=400, background_color=\"white\",\n",
    "        max_words=300, stopwords=combined_stopwords,\n",
    "        mask=mask_image, contour_width=3, contour_color=\"skyblue\",\n",
    "        colormap=\"plasma\", prefer_horizontal=0.9\n",
    "    )\n",
    "    wc.generate_from_frequencies(freqs)\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.imshow(wc, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Word Cloud {start_date} to {end_date}\", fontsize=18)\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8f7af4",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def update_outputs(*_):\n",
    "    \"\"\"Refresh map, sentiment chart, and word cloud when inputs change.\"\"\"\n",
    "    start, end = start_picker.value, end_picker.value\n",
    "    if not start or not end or start > end:\n",
    "        for out in (map_out, chart_out, wc_out):\n",
    "            with out:\n",
    "                clear_output()\n",
    "                print(\"Invalid date range\")\n",
    "        return\n",
    "    df = fetch_filtered_data(start, end)\n",
    "    with map_out:\n",
    "        clear_output(wait=True)\n",
    "        draw_map(df, start, end, choropleth_cb.value, heatmap_cb.value)\n",
    "    with chart_out:\n",
    "        clear_output(wait=True)\n",
    "        draw_sentiment_chart(df)\n",
    "    with wc_out:\n",
    "        clear_output(wait=True)\n",
    "        draw_wordcloud(df, start, end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36b5e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# — 创建并展示交互式控件 —\n",
    "fb_blue = \"#3b5998\"\n",
    "before_btn = widgets.Button(description=\"Before Election\", layout=widgets.Layout(width=\"150px\"))\n",
    "after_btn  = widgets.Button(description=\"After Election\",  layout=widgets.Layout(width=\"150px\"))\n",
    "choropleth_cb = widgets.Checkbox(value=True, description=\"Show Choropleth\")\n",
    "heatmap_cb    = widgets.Checkbox(value=True, description=\"Show HeatMap\")\n",
    "start_picker  = widgets.DatePicker(description=\"Start Date\", value=datetime.date(2025,4,15))\n",
    "end_picker    = widgets.DatePicker(description=\"End Date\",   value=datetime.date(2025,4,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e62c48",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "map_out   = widgets.Output()\n",
    "chart_out = widgets.Output()\n",
    "wc_out    = widgets.Output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd96bf71",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def select_btn(sel, unsel):\n",
    "    sel.style.button_color   = fb_blue\n",
    "    sel.style.font_color    = \"white\"\n",
    "    unsel.style.button_color = \"white\"\n",
    "    unsel.style.font_color  = fb_blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23840eb6",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def on_before(b):\n",
    "    select_btn(before_btn, after_btn)\n",
    "    start_picker.value = datetime.date(2025,3,1)\n",
    "    end_picker.value   = datetime.date(2025,5,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf6b3dd",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def on_after(b):\n",
    "    select_btn(after_btn, before_btn)\n",
    "    start_picker.value = datetime.date(2025,5,4)\n",
    "    end_picker.value   = datetime.date(2025,5,14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efda2da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_btn.on_click(on_before)\n",
    "after_btn.on_click(on_after)\n",
    "for w in (start_picker, end_picker, choropleth_cb, heatmap_cb):\n",
    "    w.observe(update_outputs, names=\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5312288",
   "metadata": {},
   "outputs": [],
   "source": [
    "ui = widgets.VBox([\n",
    "    widgets.HBox([before_btn, after_btn]),\n",
    "    widgets.HBox([start_picker, end_picker]),\n",
    "    widgets.HBox([choropleth_cb, heatmap_cb]),\n",
    "    widgets.Label(\"Map Display\"),    map_out,\n",
    "    widgets.Label(\"Sentiment Chart\"), chart_out,\n",
    "    widgets.Label(\"Word Cloud\"),      wc_out\n",
    "])\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bfacfb",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "select_btn(before_btn, after_btn)\n",
    "update_outputs()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
